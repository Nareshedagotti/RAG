{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcfOPxcGj7BylIHPH3jK7y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nareshedagotti/RAG/blob/main/Standard_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UGzlin-t_XO",
        "outputId": "51496dae-6c6b-45b1-e2dd-6ff238e392fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting groq\n",
            "  Downloading groq-0.25.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.60)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading groq-0.25.0-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m950.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, python-docx, PyPDF2, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, httpx-sse, faiss-cpu, typing-inspect, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pydantic-settings, nvidia-cusolver-cu12, groq, dataclasses-json, langchain-community\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed PyPDF2-3.0.1 dataclasses-json-0.6.7 faiss-cpu-1.11.0 groq-0.25.0 httpx-sse-0.4.0 langchain-community-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydantic-settings-2.9.1 python-docx-1.1.2 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain groq faiss-cpu sentence-transformers PyPDF2 python-docx langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text extraction\n",
        "from PyPDF2 import PdfReader\n",
        "from docx import Document\n",
        "\n",
        "def extract_text(file_paths):\n",
        "    documents = []\n",
        "    for file_path in file_paths:\n",
        "        if file_path.endswith('.pdf'):\n",
        "            with open(file_path, 'rb') as file:\n",
        "                pdf_reader = PdfReader(file)\n",
        "                text = \"\".join(page.extract_text() or \"\" for page in pdf_reader.pages)\n",
        "                documents.append({\"content\": text, \"source\": file_path})\n",
        "        elif file_path.endswith('.docx'):\n",
        "            doc = Document(file_path)\n",
        "            text = \"\\n\".join(para.text for para in doc.paragraphs)\n",
        "            documents.append({\"content\": text, \"source\": file_path})\n",
        "    return documents\n",
        "\n",
        "file_path = [\"/content/How Vectors - 1_merged.pdf\" ]\n",
        "text = extract_text(file_path)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkaJsgnduAGI",
        "outputId": "9089d8dd-260b-482a-f053-5deacbb4bc9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'content': 'HOW \\nVECTORS ARE STORED,\\n INDEXED, AND RETRIEVED\\nINTRODUCTION\\nHow text is converted into vectors, stored in a database, \\nindexed efficiently, and used to retrieve similar \\ninformation — with code & real-world examples.\\nSTATFUSIONAI\"Let\\'s go deep behind the scenes.\"\\nTEXT TO VECTOR – EMBEDDING\\nCode:\\nOutput Example:\\nfrom sentence_transformers import SentenceTransformer\\nmodel = SentenceTransformer(\\'all-MiniLM-L6-v2\\')\\ntexts = [\\n    \"Apples are sweet and red.\",\\n    \"Bananas are yellow and soft.\",\\n    \"Kids love mangoes during summer.\"\\n]\\nembeddings = model.encode(texts)\\nBehind the Scenes: \\n•When model.encode() runs, it:\\n1.Tokenizes text → converts to word pieces (subwords like \\n\"embed\" + \"##ding\")\\n2.Feeds tokens through transformer layers with attention \\nmechanisms\\n3.Pools token representations to create a single vector\\n4.Outputs a vector (384 dimensions) representing semantic \\nmeaning\\nprint(embeddings[0][:5])  # First 5 values of first embedding\\n# [0.1213, 0.3421, -0.5632, 0.1834, 0.0507]\\nprint(embeddings.shape)\\n# (3, 384) - 3 texts, each with 384-dimensional vectors\\nSTATFUSIONAIHOW EMBEDDINGS \\nARE STORED IN A VECTOR DATABASE\\n# Example using Chroma\\nimport chromadb\\nclient = chromadb.Client()\\ncollection = client.create_collection(\"fruit_facts\")\\ncollection.add(\\n    ids=[\"text1\", \"text2\", \"text3\"],\\n    embeddings=[\\n        [0.12, 0.34, -0.22],  # Simplified for demo (really 384-dim)\\n        [0.41, -0.18, 0.65],\\n        [0.22, 0.17, -0.34]\\n    ],\\n    metadatas=[\\n        {\"text\": \"Apples are red\", \"page\": 1},\\n        {\"text\": \"Bananas are yellow\", \"page\": 2},\\n        {\"text\": \"Kids love mangoes\", \"page\": 3}\\n    ]\\n)Chunk ID\\ntext1\\ntext2\\ntext3\"Apples are red.\"\\n\"Bananas are yellow.\"\\n\"Kids love mangoes.\"[0.12, 0.34, -0.22, ...]\\n[0.41, -0.18, 0.65, ...]\\n[0.22, 0.17, -0.34, ...]page: \"1\"\\npage: \"2\"\\npage: \"3\"Text Chunk Vector (Embedding) MetadataConceptual View (For Understanding):\\nActual Storage Inside Vector DB:Note: This looks like a table, but vector databases use specialized data structures.\\nSTATFUSIONAI•Vectors are stored in specialized data structures optimized for \\nsimilarity search:\\n•HNSW (Hierarchical Navigable Small World) - graph-based \\nindex\\n•IVF (Inverted File) - clustering-based index\\n•Flat - brute force comparison (simple but slow)\\n•Metadata is stored separately in a key-value store or document \\nDB\\n•IDs link the vector index with the metadata storeWhat\\'s Happening Under the Hood:\\n# Pseudocode for what\\'s happening internally\\nvector_index[\"text1\"] = [0.12, 0.34, -0.22, ...]   # Goes to optimized \\nvector index\\nmetadata_store[\"text1\"] = {                        # Goes to metadata \\nstore\\n    \"text\": \"Apples are red\",\\n    \"page\": 1\\n}\\nSTATFUSIONAISwipe\\nWhat is Indexing in VectorDBs?\\nIndexing is a fundamental technique used to organize vector data for efficient \\nsimilarity search operations. In the context of vector databases, indexing creates \\nspecialized data structures that make nearest neighbor search operations faster \\nand more efficient, especially when dealing with high-dimensional embeddings \\nfrom text, images, audio, or other data types.\\nWhy Indexing Matters\\n•Raw vector comparison (brute force) becomes prohibitively slow as datasets \\ngrow\\n•Dimensionality curse makes searching in high-dimensional spaces challenging\\n•Properly indexed data can deliver results orders of magnitude faster\\n•Enables practical applications of vector search in production environments\\nTwo Major Categories of Indexing\\n1.Exact Indexing\\n•Guarantees 100% accurate results\\n•Generally slower but provides perfect recall\\n•Example: Flat (brute-force) index\\n2.   Approximate Indexing (ANN - Approximate Nearest Neighbors)\\n•Trades a small amount of accuracy for significant speed gains\\n•Uses various techniques to efficiently narrow down the search space\\n•Examples: IVF, HNSW, PQ, ANNOY\\nDistance Metrics in Vector Search\\nThe choice of distance metric is critical in vector search:\\n•Euclidean Distance (L2): Measures straight-line distance between vectors\\n•Cosine Similarity: Measures the cosine of the angle between vectors (similarity \\nof orientation)\\n•Dot Product: Inner product between vectors (works well with normalized vectors)\\n•Manhattan Distance (L1): Sum of absolute differences between vectors\\n•Hamming Distance: For binary vectors, counts positions where bits differ\\nSTATFUSIONAIINDEXING IN VECTOR DATABASESSTATFUSIONAIFLAT (BRUTE-FORCE) INDEX\\nWhat is the Flat Index?\\nA flat index is the simplest indexing method that performs an exhaustive search by \\ncomparing the query vector with every vector in the database.\\nWhen to Use Flat Index\\n•Small to medium datasets (typically ≤100K vectors)\\n•When 100% accuracy is critical (e.g., security applications, financial matching)\\n•During development and testing to establish baseline performance\\n•When the dimensionality of vectors is relatively low\\nHow Flat Index Works\\n•No preprocessing or clustering is performed\\n•All vectors are stored in their original form\\n•Each query requires direct distance computation with every stored vector\\n•Typically uses Euclidean (L2) distance or cosine similarity\\nImplementation Example (FAISS)\\nimport faiss\\nimport numpy as np\\n# Create sample data\\ndimension = 128\\nnum_vectors = 10000\\nvectors = np.random.random((num_vectors, \\ndimension)).astype(\\'float32\\')\\n# Create a flat index with L2 distance\\nindex_flat_l2 = faiss.IndexFlatL2(dimension)\\n# For cosine similarity, normalize vectors and use dot product\\nindex_flat_ip = faiss.IndexFlatIP(dimension)  # IP = Inner Product\\n# Add vectors to the index\\nindex_flat_l2.add(vectors)\\n# Search\\nk = 5  # Number of nearest neighbors to retrieve\\nquery = np.random.random((1, dimension)).astype(\\'float32\\')\\ndistances, indices = index_flat_l2.search(query, k)\\nSTATFUSIONAIAdvantages\\n•Simple implementation requiring no training phase\\n•100% accurate results (exact nearest neighbors)\\n•Works with any distance metric\\n•No hyperparameters to tune\\nDisadvantages\\n•Search time grows linearly with dataset size (O(n) complexity)\\n•Memory intensive as all vectors must be stored in full precision\\n•Becomes impractical for large datasetsSTATFUSIONAIINVERTED FILE INDEX (IVF)\\nWhat is IVF?\\nIVF organizes vectors into clusters (using algorithms like k-means) and narrows \\nsearch to only the most relevant clusters, dramatically speeding up search on large \\ndatasets.\\nWhen to Use IVF\\n•Medium to large datasets (1M+ vectors)\\n•When you need a balance between speed and accuracy\\n•When you can accept approximate results (small accuracy trade-off)\\n•When you have a representative sample for training\\nHow IVF Works\\n1.Training phase: Vectors are clustered into nlist clusters (centroids)\\n2.Assignment phase: Each vector is assigned to its nearest centroid\\n3.Search phase:\\n•Query vector is compared to all centroids\\n•Only vectors in the nprobe nearest clusters are examined\\n•nprobe is a tunable parameter that balances speed vs. accuracy\\nDistance Metrics\\n•Uses the same distance metrics as flat indexes (typically L2 or cosine)\\n•The choice affects both clustering and search phases\\nSTATFUSIONAITuning IVF Parameters\\n•nlist (number of clusters): Higher values = faster search but lower accuracy\\n•Rule of thumb: nlist = sqrt(N) where N is dataset size\\n•nprobe (clusters to search): Higher values = higher accuracy but slower search\\n•Typical values: 1-10% of nlist\\nAdvantages\\n•Much faster than flat index for large datasets\\n•Scalable to millions of vectors\\n•Adaptable trade-off between speed and accuracy via nprobe\\nDisadvantages\\n•Requires a training phase with representative data\\n•Not 100% accurate (may miss some relevant vectors)\\n•Performance depends on data distribution and clustering qualityImplementation Example (FAISS)\\nimport faiss\\nimport numpy as np\\ndimension = 128\\nnum_vectors = 1000000\\nvectors = np.random.random((num_vectors, \\ndimension)).astype(\\'float32\\')\\n# Create quantizer (the index for centroids)\\nquantizer = faiss.IndexFlatL2(dimension)\\n# Create the IVF index\\nnlist = 100  # Number of clusters\\nindex_ivf = faiss.IndexIVFFlat(quantizer, dimension, nlist, \\nfaiss.METRIC_L2)\\n# Must train the index with representative data\\nindex_ivf.train(vectors[:100000])  # Can use subset for training\\nindex_ivf.add(vectors)\\n# Set search parameters\\nindex_ivf.nprobe = 10  # Number of clusters to visit during searchSTATFUSIONAIWhat is Product Quantization?\\nPQ is a compression technique that reduces the memory footprint of vectors by \\nencoding them into compact codes, making it possible to store and search billions \\nof vectors efficiently.\\nWhen to Use PQ\\n•Very large datasets (10M+ vectors)\\n•Memory-constrained environments\\n•When speed and memory efficiency are more important than perfect accuracy\\n•Often combined with IVF for better performance (IVF-PQ)\\nHow PQ Works\\n1.Vector splitting: Each vector is divided into M equal sub-vectors\\n2.Codebook generation: For each sub-vector space, k-means clustering creates a \\ncodebook\\n3.Quantization: Each sub-vector is replaced by its nearest centroid\\'s index\\n4.Storage: Instead of storing the full vector, only centroid indices are stored\\n5.Distance approximation: Distances are computed using pre-computed lookup \\ntables\\nDistance Considerations with PQ\\n•PQ works best with Euclidean (L2) distance\\n•For cosine similarity, vectors should be normalized before quantization\\n•Distance computations are approximated, affecting accuracyPRODUCT QUANTIZATION (PQ)\\nSTATFUSIONAIImplementation Example (FAISS)\\nimport faiss\\nimport numpy as np\\ndimension = 128\\nnum_vectors = 10000000\\nvectors = np.random.random((num_vectors, \\ndimension)).astype(\\'float32\\')\\n# Create quantizer\\nquantizer = faiss.IndexFlatL2(dimension)\\n# Create an IVF-PQ index\\nnlist = 1000  # Number of clusters\\nm = 8         # Number of subquantizers\\nnbits = 8     # Bits per subquantizer (256 centroids per subquantizer)\\nindex_ivfpq = faiss.IndexIVFPQ(quantizer, dimension, nlist, m, nbits)\\n# Train and add vectors\\nindex_ivfpq.train(vectors[:100000])\\nindex_ivfpq.add(vectors)\\n# Set search parameters\\nindex_ivfpq.nprobe = 20  # Number of clusters to search\\nTuning PQ Parameters\\n•m (number of subquantizers): Higher values = better accuracy but larger codes\\n•nbits (bits per subquantizer): Usually 8 (256 centroids per subquantizer)\\n•nlist and nprobe: Same as in IVF\\nAdvantages\\n•Extremely memory efficient (can reduce memory by 10-100x)\\n•Enables searching billions of vectors on standard hardware\\n•Fast distance computations using lookup tables\\nDisadvantages\\n•Lower accuracy compared to flat or IVF indexes\\n•Complex setup with multiple hyperparameters\\n•Performance highly dependent on data characteristicsSTATFUSIONAIGRAPH-BASED INDEXING (HNSW)\\nWhat is HNSW?\\nHierarchical Navigable Small World (HNSW) is a graph-based indexing method that \\ncreates a multi-layered graph structure for efficient navigation to nearest \\nneighbors.\\nWhen to Use HNSW\\n•Medium to large datasets where search speed is critical\\n•Real-time applications requiring low latency\\n•When high accuracy is important, but you can\\'t use flat index\\n•When you have sufficient memory to store the graph structure\\nHow HNSW Works\\n1.Graph construction: Each vector becomes a node connected to its neighbors\\n2.Hierarchical structure: Multiple layers with varying connection densities\\n3.Search process:\\n•Start at entry point in the top layer\\n•Greedily move to closer neighbors\\n•Descend through layers, refining the search\\n•Stop at the bottom layer with the best candidates\\nDistance Metrics in HNSW\\n•Works with any distance metric (L2, cosine, etc.)\\n•Distance calculations are exact, but search path is approximate\\n•The choice of metric affects both graph construction and search\\nWhat is HNSW?\\nHierarchical Navigable Small World (HNSW) is a graph-based indexing method that \\ncreates a multi-layered graph structure for efficient navigation to nearest \\nneighbors.\\nWhen to Use HNSW\\n•Medium to large datasets where search speed is critical\\n•Real-time applications requiring low latency\\n•When high accuracy is important, but you can\\'t use flat index\\n•When you have sufficient memory to store the graph structure\\nHow HNSW Works\\n1.Graph construction: Each vector becomes a node connected to its neighbors\\n2.Hierarchical structure: Multiple layers with varying connection densities\\n3.Search process:\\n•Start at entry point in the top layer\\n•Greedily move to closer neighbors\\n•Descend through layers, refining the search\\n•Stop at the bottom layer with the best candidates\\nDistance Metrics in HNSW\\n•Works with any distance metric (L2, cosine, etc.)\\n•Distance calculations are exact, but search path is approximate\\n•The choice of metric affects both graph construction and searchSTATFUSIONAIImplementation Example (FAISS)\\nimport faiss\\nimport numpy as np\\ndimension = 128\\nnum_vectors = 1000000\\nvectors = np.random.random((num_vectors, \\ndimension)).astype(\\'float32\\')\\n# Create HNSW index\\nM = 16    # Number of connections per layer\\nefC = 100  # Construction-time exploration factor\\nindex_hnsw = faiss.IndexHNSWFlat(dimension, M)\\nindex_hnsw.hnsw.efConstruction = efC\\nindex_hnsw.hnsw.efSearch = 64  # Search-time exploration factor\\n# Add vectors (no separate training needed)\\nindex_hnsw.add(vectors)\\nTuning HNSW Parameters\\n•M (connections per node): Higher values = better accuracy but more memory\\n•Typical values: 16-64\\n•efConstruction (build-time accuracy): Higher values = better index quality but \\nslower build\\n•Typical values: 100-500\\n•efSearch (search-time accuracy): Higher values = better search accuracy but \\nslower search\\n•Can be adjusted at query time\\nAdvantages\\n•Excellent balance of speed and accuracy\\n•No training phase required\\n•Dynamic updates possible (can add vectors after construction)\\n•Works well with filtered queries\\nDisadvantages\\n•Memory intensive (stores both vectors and graph links)\\n•Index construction can be slow\\n•More complex implementation than other methodsSTATFUSIONAISCALAR QUANTIZATION (SQ)\\nWhat is Scalar Quantization?\\nScalar Quantization reduces the precision of vector components (e.g., from 32-bit \\nfloat to 8-bit integer) to decrease memory usage while maintaining reasonable \\naccuracy.\\nWhen to Use SQ\\n•When you need moderate memory savings with minimal accuracy loss\\n•As a simpler alternative to PQ when extreme compression isn\\'t needed\\n•Can be combined with other index types (Flat-SQ, IVF-SQ, etc.)\\nHow SQ Works\\n1.Determine the range of values in each dimension\\n2.Map these ranges to fixed-bit representations (typically 8-bit)\\n3.Convert each floating-point value to its quantized form\\nDistance Considerations\\n•Works with both L2 distance and inner product (cosine similarity)\\n•Slightly reduced accuracy due to quantization error\\n•Computations may be faster due to integer arithmetic\\nImplementation Example (FAISS)\\nimport faiss\\nimport numpy as np\\ndimension = 128\\nnum_vectors = 1000000\\nvectors = np.random.random((num_vectors, \\ndimension)).astype(\\'float32\\')\\n# Create Scalar Quantized index\\nindex_sq = faiss.IndexScalarQuantizer(dimension, \\nfaiss.ScalarQuantizer.QT_8bit, faiss.METRIC_L2)\\n# Alternative: combine with IVF\\nquantizer = faiss.IndexFlatL2(dimension)\\nindex_ivfsq = faiss.IndexIVFScalarQuantizer(quantizer, dimension, 1000, \\n                                           faiss.ScalarQuantizer.QT_8bit, faiss.METRIC_L2)\\n# Train and add vectors\\nindex_ivfsq.train(vectors[:100000])\\nindex_ivfsq.add(vectors)\\nAdvantages\\n•Simple implementation and concept\\n•Moderate memory savings (4x compared to 32-bit floats)\\n•Minimal accuracy impact\\nDisadvantages\\n•Less compression than PQ\\n•Still requires significant memory for large datasets\\nSTATFUSIONAIVECTORDB SPECIFIC INDEXING FEATURES\\nVector \\nDatabaseSupported \\nIndex TypesDistance \\nMetricsAuto-Indexing? Key Features\\nFAISS Flat, IVF, PQ, \\nHNSW, SQ, LSH, \\ncombinationsL2, Cosine, Dot \\nProduct\\nHighly \\ncustomizable, \\nGPU support\\nPinecone Proprietary \\n(HNSW-based)Cosine, Dot \\nProduct, \\nEuclidean\\nFully managed, \\nserverless, auto-\\nscaling\\nWeaviate HNSW, Flat Cosine\\n Schema-based, \\nmulti-modal, \\nGraphQL API\\nQdrant HNSW, Scalar \\nQuantizationCosine, Dot \\nProduct, \\nEuclidean\\npayload storage\\nMilvus IVF, HNSW, \\nPQ, ANNOY, \\ncombinationsEuclidean, IP, \\nJaccard, others\\nHybrid search, \\ncloud/self-\\nhosted\\nChroma HNSW Cosine, L2, IP\\n Simple API, \\nembedding \\nfunction \\nintegration\\nElasticsearch HNSW Cosine, Dot \\nProduct, L2\\nText+vector \\nsearch, mature \\necosystem\\npgvector IVF, HNSW Cosine, L2, IP\\n Postgres \\nextension, \\nfamiliar SQL \\ninterfaceMajor Vector Database Comparison\\nSTATFUSIONAISpecial Features by Database\\nFAISS\\n•Supports GPU acceleration for both indexing and search\\n•Provides multi-GPU and distributed search capabilities\\n•Allows custom combination of index types (e.g., IVF + PQ + SQ)\\nPinecone\\n1.Automatic index selection and optimization\\n2.Namespace support for logical data separation\\n3.Handles pod-based scaling for high throughput\\nWeaviate\\n•Modular architecture with multi-modal search\\n•Contextionization for dynamic vector generation\\n•BM25/TF-IDF hybrid search with vector search\\nQdrant\\n•Advanced payload filtering with vector search\\n•Payload-based negative filtering for search results\\n•Optimized disk storage with memory-mapped files\\nMilvus\\n•Dynamic schema changes without reindexing\\n•Scalar, vector, and hybrid search capabilities\\n•Time travel queries (historical data access)\\nSTATFUSIONAICHOOSING THE RIGHT INDEX\\nDecision Framework\\nGuidance by Data SizeQuestion Use Case Example Recommended \\nIndexDistance Metric\\nDo you need 100% \\naccuracy?Financial transaction \\nmatchingFlat Index Typically L2 or cosine\\nDo you have millions \\nof vectors?Large-scale \\nsemantic searchIVF or HNSW Cosine for text, L2 for \\nimages\\nIs speed more \\nimportant than \\naccuracy?Real-time product \\nrecommendationsHNSW Cosine similarity\\nAre you on low \\nmemory hardware?Mobile or embedded \\nsearchIVF-PQ or SQ L2 often preferred\\nDo you need \\nincremental \\nupdates?Dynamic document \\ndatabaseHNSW Any, depending on \\ndata\\nIs your data high-\\ndimensional (500+)?Large language \\nmodel embeddingsPQ + IVF Cosine similarity\\nDataset Size First Choice Alternative Notes\\n< 100K vectors Flat HNSW Flat for simplicity, \\nHNSW if query speed \\ncritical\\n100K - 1M vectors HNSW IVF HNSW for better \\naccuracy-speed \\ntradeoff\\n1M - 10M vectors IVF-HNSW IVF Combined approach \\nfor balanced \\nperformance\\n10M - 100M vectors IVF-PQ IVF-SQ Compression \\nbecomes necessary\\n> 100M vectors IVF-PQ Distributed HNSW Must consider \\ndistribution \\nor extreme \\ncompression\\nSTATFUSIONAIHOW INDEXING WORKS \\n– FAISS EXAMPLE\\nCode:\\nimport faiss\\nimport numpy as np\\n# Convert embeddings to numpy array (float32 required by FAISS)\\nembeddings_np = np.array(embeddings).astype(\\'float32\\')\\n# Get dimensionality of vectors\\nd = embeddings_np.shape[1]  # 384 dimensions\\n# Create a flat index (brute force search)\\nindex = faiss.IndexFlatL2(d)  # L2 = Euclidean distance\\n# Add vectors to the index\\nindex.add(embeddings_np)\\nBehind the Scenes: \\n•FAISS creates a data structure to efficiently find similar vectors\\n•For a Flat index:\\n•Vectors are stored contiguously in memory for cache efficiency\\n•Uses SIMD (Single Instruction Multiple Data) for parallel computation\\n•Calculates distances between ALL vectors during search (brute force)\\n•For more advanced indices like HNSW:\\n•Builds a navigable graph structure with multiple layers\\n•Vectors become nodes connected to similar vectors\\n•Search follows connections to quickly find similar vectors\\nOutput Example:\\nprint(f\"FAISS index contains {index.ntotal} vectors of dimension {d}\")\\n# FAISS index contains 3 vectors of dimension 384\\nSTATFUSIONAICREATING ADVANCED INDICES \\nFOR FASTER RETRIEVAL\\nCode:\\n# Create an HNSW index (much faster for large datasets)\\nnlist = 1     # Number of clusters (use higher for millions of vectors)\\nM = 16        # Number of connections per layer (higher = more \\naccurate, slower)\\nef_construction = 200  # Controls index quality\\nindex_hnsw = faiss.IndexHNSWFlat(d, M)\\nindex_hnsw.hnsw.efConstruction = ef_construction\\nindex_hnsw.add(embeddings_np)\\nBehind the Scenes: \\n•Hierarchical Navigable Small World creates a multi-layer graph\\n•Each vector connects to M most similar vectors\\n•Creates \"shortcuts\" through vector space\\n•During construction:\\n1.Insert vector at top layer\\n2.Navigate down through layers using greedy search\\n3.Connect to nearest neighbors at each layer\\n4.Maintain max connections per node (M)\\nVisualization:\\nLayer 2:  •───•\\n                 │   \\nLayer 1:  •───•───•\\n                 │   │   │\\nLayer 0:  •───•───•───•───•───•\\n               All vectors in bottom layer\\nSTATFUSIONAIRETRIEVING \\nSIMILAR CHUNKS\\nCode:\\n# Create a query vector\\nquery_text = \"Which fruit is red?\"\\nquery_vector = model.encode([query_text])[0].astype(\\'float32\\')\\n# Search the index\\nk = 2  # Return top 2 results\\ndistances, indices = \\nindex.search(np.array([query_vector]).astype(\\'float32\\'), k)\\n# Display results\\nprint(f\"Top {k} matches for \\'{query_text}\\':\")\\nfor i, (dist, idx) in enumerate(zip(distances[0], indices[0])):\\n    print(f\"{i+1}. Text: \\'{texts[idx]}\\' (Distance: {dist:.4f})\")\\nBehind the Scenes: \\n1.Query text is converted to a vector using same model\\n2.Vector DB performs distance calculations:\\n•For Flat index: Computes distance to EVERY vector (O(n))\\n•For HNSW index: Traverses graph structure (O(log n))\\n3.  Returns indices of closest vectors and their distances\\nOutput:\\nTop 2 matches for \\'Which fruit is red?\\':\\n1. Text: \\'Apples are sweet and red.\\' (Distance: 0.7234)\\n2. Text: \\'Bananas are yellow and soft.\\' (Distance: 1.2156)\\nSTATFUSIONAIHOW SIMILARITY IS \\nCALCULATED\\nMathematical Understanding:\\n•Euclidean: Straight-line distance between points in vector space\\n•Formula: sqrt(sum((a_i - b_i)²))\\n•Cosine: Angle between vectors (ignores magnitude)\\n•Formula: dot(a, b) / (||a|| * ||b||)\\n•After normalization, dot product = cosine similarityDifferent similarity metrics can be used, affecting how \"closeness\" is measured:\\nEuclidean Distance (L2):\\n# Already used in our FAISS example\\nindex = faiss.IndexFlatL2(d)  # Lower value = more similar\\nCosine Similarity:\\n# Normalize vectors for cosine similarity\\nfaiss.normalize_L2(embeddings_np)  # In-place normalization\\n# Create index that measures inner product (dot product)\\nindex_ip = faiss.IndexFlatIP(d)    # Higher value = more similar\\nindex_ip.add(embeddings_np)        # Add normalized vectors\\n# Normalize query for search\\nquery_vector_norm = query_vector.copy()\\nfaiss.normalize_L2(np.array([query_vector_norm]).astype(\\'float32\\'))\\nSTATFUSIONAIREAL-WORLD USE CASE: \\nBUILDING A SIMPLE Q&A SYSTEM\\nComplete Working Example:\\nimport numpy as np\\nfrom sentence_transformers import SentenceTransformer\\nimport faiss\\n# 1. Create a knowledge base\\ndocuments = [\\n    \"Apples are red or green fruits that grow on trees.\",\\n    \"Bananas are yellow fruits with a soft texture inside.\",\\n    \"Oranges are citrus fruits known for vitamin C content.\",\\n    \"Strawberries are red berries with seeds on the outside.\",\\n    \"Blueberries are small blue fruits rich in antioxidants.\"\\n]\\n# 2. Convert to embeddings\\nmodel = SentenceTransformer(\\'all-MiniLM-L6-v2\\')\\ndocument_embeddings = \\nmodel.encode(documents).astype(\\'float32\\')\\n# 3. Create and populate index\\ndimension = document_embeddings.shape[1]\\nindex = faiss.IndexFlatL2(dimension)\\nindex.add(document_embeddings)\\n# 4. Function to answer questions\\ndef answer_question(question, index, documents, model, k=2):\\n    # Convert question to vector\\n    query_vector = model.encode([question]).astype(\\'float32\\')\\nSTATFUSIONAI    # Search\\n    distances, indices = index.search(query_vector, k)\\n    \\n    print(f\"Question: {question}\\\\n\")\\n    print(\"Top relevant information:\")\\n    for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):\\n        print(f\"{i+1}. {documents[idx]} (Distance: {dist:.4f})\")\\n    \\n    print(\"\\\\n---\\\\n\")\\n# 5. Try it out\\nquestions = [\\n    \"What color are apples?\"\\n]\\nfor question in questions:\\n    answer_question(question, index, documents, model)\\nSystem Output:\\nQuestion: What color are apples?\\nTop relevant information:\\n1. Apples are red or green fruits that grow on trees. (Distance: 0.5008)\\n2. Bananas are yellow fruits with a soft texture inside. (Distance: 1.0824)\\nSTATFUSIONAIREAL-LIFE ANALOGY\\nVector databases are like Google Maps for ideas:\\n•Vector space is like a vast landscape of meaning\\n•Embedding model is like a coordinate system\\n•Indexing creates highways and shortcuts for faster travel\\n•Query is your starting point\\n•Similarity search finds the closest \"locations\" in meaning-space\\n•\\nApplications:\\n•Semantic search engines\\n•Chatbot memory & knowledge retrieval\\n•Recommendation systems\\n•Content discovery\\n•Document deduplication\\nSTATFUSIONAISUMMARY\\nKey Insight:  Vector databases bridge the gap between human language and    \\nmachine understanding, enabling semantic search beyond keyword matching.Step Descr iption Code E xample What Happens\\n1. Embedding Convert t ext to vec-\\ntorsmodel.enc ode(t exts) Neur al netw ork tr ansf orms \\ntext to numeric al represen -\\ntation\\n2. St orage Save v ectors in DB collection.add(...) Vectors st ored in specializ ed \\nstructures + metadata in KV \\nstore\\n3. Inde xing\\nsearch structurefaiss.In -\\ndexHNSWFlat(d, M)Creat es gr aph or clust ers f or \\nfast na vigation\\n4. Quer y Convert question t o \\nvectormodel.enc ode([que-\\nry])Same proc ess as original t ext\\n5. Retrie val Find similar v ectors inde x.search(que -\\nry_vector, k)Finds nearest neighbors us-\\ning distanc e metric\\n', 'source': '/content/How Vectors - 1_merged.pdf'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting text into chunkings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def chunk_text(documents):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
        "    chunks = []\n",
        "    for doc in documents:\n",
        "        split_docs = text_splitter.create_documents(\n",
        "            [doc[\"content\"]],\n",
        "            metadatas=[{\"source\": doc[\"source\"]}]\n",
        "        )\n",
        "        chunks.extend(split_docs)\n",
        "    return chunks\n",
        "\n",
        "chunks = chunk_text(text)\n",
        "for i, chunk in enumerate(chunks, 1):\n",
        "    print(f\"\\n🔹 **Chunk {i}:**\\n{chunk.page_content}\\n{'-'*50}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl54YDC9uAIy",
        "outputId": "64af969d-21c4-43e4-9209-c69beb73c40e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 **Chunk 1:**\n",
            "HOW \n",
            "VECTORS ARE STORED,\n",
            " INDEXED, AND RETRIEVED\n",
            "INTRODUCTION\n",
            "How text is converted into vectors, stored in a database, \n",
            "indexed efficiently, and used to retrieve similar \n",
            "information — with code & real-world examples.\n",
            "STATFUSIONAI\"Let's go deep behind the scenes.\"\n",
            "TEXT TO VECTOR – EMBEDDING\n",
            "Code:\n",
            "Output Example:\n",
            "from sentence_transformers import SentenceTransformer\n",
            "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
            "texts = [\n",
            "    \"Apples are sweet and red.\",\n",
            "    \"Bananas are yellow and soft.\",\n",
            "    \"Kids love mangoes during summer.\"\n",
            "]\n",
            "embeddings = model.encode(texts)\n",
            "Behind the Scenes: \n",
            "•When model.encode() runs, it:\n",
            "1.Tokenizes text → converts to word pieces (subwords like \n",
            "\"embed\" + \"##ding\")\n",
            "2.Feeds tokens through transformer layers with attention \n",
            "mechanisms\n",
            "3.Pools token representations to create a single vector\n",
            "4.Outputs a vector (384 dimensions) representing semantic \n",
            "meaning\n",
            "print(embeddings[0][:5])  # First 5 values of first embedding\n",
            "# [0.1213, 0.3421, -0.5632, 0.1834, 0.0507]\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 2:**\n",
            "# [0.1213, 0.3421, -0.5632, 0.1834, 0.0507]\n",
            "print(embeddings.shape)\n",
            "# (3, 384) - 3 texts, each with 384-dimensional vectors\n",
            "STATFUSIONAIHOW EMBEDDINGS \n",
            "ARE STORED IN A VECTOR DATABASE\n",
            "# Example using Chroma\n",
            "import chromadb\n",
            "client = chromadb.Client()\n",
            "collection = client.create_collection(\"fruit_facts\")\n",
            "collection.add(\n",
            "    ids=[\"text1\", \"text2\", \"text3\"],\n",
            "    embeddings=[\n",
            "        [0.12, 0.34, -0.22],  # Simplified for demo (really 384-dim)\n",
            "        [0.41, -0.18, 0.65],\n",
            "        [0.22, 0.17, -0.34]\n",
            "    ],\n",
            "    metadatas=[\n",
            "        {\"text\": \"Apples are red\", \"page\": 1},\n",
            "        {\"text\": \"Bananas are yellow\", \"page\": 2},\n",
            "        {\"text\": \"Kids love mangoes\", \"page\": 3}\n",
            "    ]\n",
            ")Chunk ID\n",
            "text1\n",
            "text2\n",
            "text3\"Apples are red.\"\n",
            "\"Bananas are yellow.\"\n",
            "\"Kids love mangoes.\"[0.12, 0.34, -0.22, ...]\n",
            "[0.41, -0.18, 0.65, ...]\n",
            "[0.22, 0.17, -0.34, ...]page: \"1\"\n",
            "page: \"2\"\n",
            "page: \"3\"Text Chunk Vector (Embedding) MetadataConceptual View (For Understanding):\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 3:**\n",
            "Actual Storage Inside Vector DB:Note: This looks like a table, but vector databases use specialized data structures.\n",
            "STATFUSIONAI•Vectors are stored in specialized data structures optimized for \n",
            "similarity search:\n",
            "•HNSW (Hierarchical Navigable Small World) - graph-based \n",
            "index\n",
            "•IVF (Inverted File) - clustering-based index\n",
            "•Flat - brute force comparison (simple but slow)\n",
            "•Metadata is stored separately in a key-value store or document \n",
            "DB\n",
            "•IDs link the vector index with the metadata storeWhat's Happening Under the Hood:\n",
            "# Pseudocode for what's happening internally\n",
            "vector_index[\"text1\"] = [0.12, 0.34, -0.22, ...]   # Goes to optimized \n",
            "vector index\n",
            "metadata_store[\"text1\"] = {                        # Goes to metadata \n",
            "store\n",
            "    \"text\": \"Apples are red\",\n",
            "    \"page\": 1\n",
            "}\n",
            "STATFUSIONAISwipe\n",
            "What is Indexing in VectorDBs?\n",
            "Indexing is a fundamental technique used to organize vector data for efficient \n",
            "similarity search operations. In the context of vector databases, indexing creates\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 4:**\n",
            "specialized data structures that make nearest neighbor search operations faster \n",
            "and more efficient, especially when dealing with high-dimensional embeddings \n",
            "from text, images, audio, or other data types.\n",
            "Why Indexing Matters\n",
            "•Raw vector comparison (brute force) becomes prohibitively slow as datasets \n",
            "grow\n",
            "•Dimensionality curse makes searching in high-dimensional spaces challenging\n",
            "•Properly indexed data can deliver results orders of magnitude faster\n",
            "•Enables practical applications of vector search in production environments\n",
            "Two Major Categories of Indexing\n",
            "1.Exact Indexing\n",
            "•Guarantees 100% accurate results\n",
            "•Generally slower but provides perfect recall\n",
            "•Example: Flat (brute-force) index\n",
            "2.   Approximate Indexing (ANN - Approximate Nearest Neighbors)\n",
            "•Trades a small amount of accuracy for significant speed gains\n",
            "•Uses various techniques to efficiently narrow down the search space\n",
            "•Examples: IVF, HNSW, PQ, ANNOY\n",
            "Distance Metrics in Vector Search\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 5:**\n",
            "Distance Metrics in Vector Search\n",
            "The choice of distance metric is critical in vector search:\n",
            "•Euclidean Distance (L2): Measures straight-line distance between vectors\n",
            "•Cosine Similarity: Measures the cosine of the angle between vectors (similarity \n",
            "of orientation)\n",
            "•Dot Product: Inner product between vectors (works well with normalized vectors)\n",
            "•Manhattan Distance (L1): Sum of absolute differences between vectors\n",
            "•Hamming Distance: For binary vectors, counts positions where bits differ\n",
            "STATFUSIONAIINDEXING IN VECTOR DATABASESSTATFUSIONAIFLAT (BRUTE-FORCE) INDEX\n",
            "What is the Flat Index?\n",
            "A flat index is the simplest indexing method that performs an exhaustive search by \n",
            "comparing the query vector with every vector in the database.\n",
            "When to Use Flat Index\n",
            "•Small to medium datasets (typically ≤100K vectors)\n",
            "•When 100% accuracy is critical (e.g., security applications, financial matching)\n",
            "•During development and testing to establish baseline performance\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 6:**\n",
            "•When the dimensionality of vectors is relatively low\n",
            "How Flat Index Works\n",
            "•No preprocessing or clustering is performed\n",
            "•All vectors are stored in their original form\n",
            "•Each query requires direct distance computation with every stored vector\n",
            "•Typically uses Euclidean (L2) distance or cosine similarity\n",
            "Implementation Example (FAISS)\n",
            "import faiss\n",
            "import numpy as np\n",
            "# Create sample data\n",
            "dimension = 128\n",
            "num_vectors = 10000\n",
            "vectors = np.random.random((num_vectors, \n",
            "dimension)).astype('float32')\n",
            "# Create a flat index with L2 distance\n",
            "index_flat_l2 = faiss.IndexFlatL2(dimension)\n",
            "# For cosine similarity, normalize vectors and use dot product\n",
            "index_flat_ip = faiss.IndexFlatIP(dimension)  # IP = Inner Product\n",
            "# Add vectors to the index\n",
            "index_flat_l2.add(vectors)\n",
            "# Search\n",
            "k = 5  # Number of nearest neighbors to retrieve\n",
            "query = np.random.random((1, dimension)).astype('float32')\n",
            "distances, indices = index_flat_l2.search(query, k)\n",
            "STATFUSIONAIAdvantages\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 7:**\n",
            "STATFUSIONAIAdvantages\n",
            "•Simple implementation requiring no training phase\n",
            "•100% accurate results (exact nearest neighbors)\n",
            "•Works with any distance metric\n",
            "•No hyperparameters to tune\n",
            "Disadvantages\n",
            "•Search time grows linearly with dataset size (O(n) complexity)\n",
            "•Memory intensive as all vectors must be stored in full precision\n",
            "•Becomes impractical for large datasetsSTATFUSIONAIINVERTED FILE INDEX (IVF)\n",
            "What is IVF?\n",
            "IVF organizes vectors into clusters (using algorithms like k-means) and narrows \n",
            "search to only the most relevant clusters, dramatically speeding up search on large \n",
            "datasets.\n",
            "When to Use IVF\n",
            "•Medium to large datasets (1M+ vectors)\n",
            "•When you need a balance between speed and accuracy\n",
            "•When you can accept approximate results (small accuracy trade-off)\n",
            "•When you have a representative sample for training\n",
            "How IVF Works\n",
            "1.Training phase: Vectors are clustered into nlist clusters (centroids)\n",
            "2.Assignment phase: Each vector is assigned to its nearest centroid\n",
            "3.Search phase:\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 8:**\n",
            "3.Search phase:\n",
            "•Query vector is compared to all centroids\n",
            "•Only vectors in the nprobe nearest clusters are examined\n",
            "•nprobe is a tunable parameter that balances speed vs. accuracy\n",
            "Distance Metrics\n",
            "•Uses the same distance metrics as flat indexes (typically L2 or cosine)\n",
            "•The choice affects both clustering and search phases\n",
            "STATFUSIONAITuning IVF Parameters\n",
            "•nlist (number of clusters): Higher values = faster search but lower accuracy\n",
            "•Rule of thumb: nlist = sqrt(N) where N is dataset size\n",
            "•nprobe (clusters to search): Higher values = higher accuracy but slower search\n",
            "•Typical values: 1-10% of nlist\n",
            "Advantages\n",
            "•Much faster than flat index for large datasets\n",
            "•Scalable to millions of vectors\n",
            "•Adaptable trade-off between speed and accuracy via nprobe\n",
            "Disadvantages\n",
            "•Requires a training phase with representative data\n",
            "•Not 100% accurate (may miss some relevant vectors)\n",
            "•Performance depends on data distribution and clustering qualityImplementation Example (FAISS)\n",
            "import faiss\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 9:**\n",
            "import faiss\n",
            "import numpy as np\n",
            "dimension = 128\n",
            "num_vectors = 1000000\n",
            "vectors = np.random.random((num_vectors, \n",
            "dimension)).astype('float32')\n",
            "# Create quantizer (the index for centroids)\n",
            "quantizer = faiss.IndexFlatL2(dimension)\n",
            "# Create the IVF index\n",
            "nlist = 100  # Number of clusters\n",
            "index_ivf = faiss.IndexIVFFlat(quantizer, dimension, nlist, \n",
            "faiss.METRIC_L2)\n",
            "# Must train the index with representative data\n",
            "index_ivf.train(vectors[:100000])  # Can use subset for training\n",
            "index_ivf.add(vectors)\n",
            "# Set search parameters\n",
            "index_ivf.nprobe = 10  # Number of clusters to visit during searchSTATFUSIONAIWhat is Product Quantization?\n",
            "PQ is a compression technique that reduces the memory footprint of vectors by \n",
            "encoding them into compact codes, making it possible to store and search billions \n",
            "of vectors efficiently.\n",
            "When to Use PQ\n",
            "•Very large datasets (10M+ vectors)\n",
            "•Memory-constrained environments\n",
            "•When speed and memory efficiency are more important than perfect accuracy\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 10:**\n",
            "•Often combined with IVF for better performance (IVF-PQ)\n",
            "How PQ Works\n",
            "1.Vector splitting: Each vector is divided into M equal sub-vectors\n",
            "2.Codebook generation: For each sub-vector space, k-means clustering creates a \n",
            "codebook\n",
            "3.Quantization: Each sub-vector is replaced by its nearest centroid's index\n",
            "4.Storage: Instead of storing the full vector, only centroid indices are stored\n",
            "5.Distance approximation: Distances are computed using pre-computed lookup \n",
            "tables\n",
            "Distance Considerations with PQ\n",
            "•PQ works best with Euclidean (L2) distance\n",
            "•For cosine similarity, vectors should be normalized before quantization\n",
            "•Distance computations are approximated, affecting accuracyPRODUCT QUANTIZATION (PQ)\n",
            "STATFUSIONAIImplementation Example (FAISS)\n",
            "import faiss\n",
            "import numpy as np\n",
            "dimension = 128\n",
            "num_vectors = 10000000\n",
            "vectors = np.random.random((num_vectors, \n",
            "dimension)).astype('float32')\n",
            "# Create quantizer\n",
            "quantizer = faiss.IndexFlatL2(dimension)\n",
            "# Create an IVF-PQ index\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 11:**\n",
            "# Create an IVF-PQ index\n",
            "nlist = 1000  # Number of clusters\n",
            "m = 8         # Number of subquantizers\n",
            "nbits = 8     # Bits per subquantizer (256 centroids per subquantizer)\n",
            "index_ivfpq = faiss.IndexIVFPQ(quantizer, dimension, nlist, m, nbits)\n",
            "# Train and add vectors\n",
            "index_ivfpq.train(vectors[:100000])\n",
            "index_ivfpq.add(vectors)\n",
            "# Set search parameters\n",
            "index_ivfpq.nprobe = 20  # Number of clusters to search\n",
            "Tuning PQ Parameters\n",
            "•m (number of subquantizers): Higher values = better accuracy but larger codes\n",
            "•nbits (bits per subquantizer): Usually 8 (256 centroids per subquantizer)\n",
            "•nlist and nprobe: Same as in IVF\n",
            "Advantages\n",
            "•Extremely memory efficient (can reduce memory by 10-100x)\n",
            "•Enables searching billions of vectors on standard hardware\n",
            "•Fast distance computations using lookup tables\n",
            "Disadvantages\n",
            "•Lower accuracy compared to flat or IVF indexes\n",
            "•Complex setup with multiple hyperparameters\n",
            "•Performance highly dependent on data characteristicsSTATFUSIONAIGRAPH-BASED INDEXING (HNSW)\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 12:**\n",
            "What is HNSW?\n",
            "Hierarchical Navigable Small World (HNSW) is a graph-based indexing method that \n",
            "creates a multi-layered graph structure for efficient navigation to nearest \n",
            "neighbors.\n",
            "When to Use HNSW\n",
            "•Medium to large datasets where search speed is critical\n",
            "•Real-time applications requiring low latency\n",
            "•When high accuracy is important, but you can't use flat index\n",
            "•When you have sufficient memory to store the graph structure\n",
            "How HNSW Works\n",
            "1.Graph construction: Each vector becomes a node connected to its neighbors\n",
            "2.Hierarchical structure: Multiple layers with varying connection densities\n",
            "3.Search process:\n",
            "•Start at entry point in the top layer\n",
            "•Greedily move to closer neighbors\n",
            "•Descend through layers, refining the search\n",
            "•Stop at the bottom layer with the best candidates\n",
            "Distance Metrics in HNSW\n",
            "•Works with any distance metric (L2, cosine, etc.)\n",
            "•Distance calculations are exact, but search path is approximate\n",
            "•The choice of metric affects both graph construction and search\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 13:**\n",
            "What is HNSW?\n",
            "Hierarchical Navigable Small World (HNSW) is a graph-based indexing method that \n",
            "creates a multi-layered graph structure for efficient navigation to nearest \n",
            "neighbors.\n",
            "When to Use HNSW\n",
            "•Medium to large datasets where search speed is critical\n",
            "•Real-time applications requiring low latency\n",
            "•When high accuracy is important, but you can't use flat index\n",
            "•When you have sufficient memory to store the graph structure\n",
            "How HNSW Works\n",
            "1.Graph construction: Each vector becomes a node connected to its neighbors\n",
            "2.Hierarchical structure: Multiple layers with varying connection densities\n",
            "3.Search process:\n",
            "•Start at entry point in the top layer\n",
            "•Greedily move to closer neighbors\n",
            "•Descend through layers, refining the search\n",
            "•Stop at the bottom layer with the best candidates\n",
            "Distance Metrics in HNSW\n",
            "•Works with any distance metric (L2, cosine, etc.)\n",
            "•Distance calculations are exact, but search path is approximate\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 14:**\n",
            "•The choice of metric affects both graph construction and searchSTATFUSIONAIImplementation Example (FAISS)\n",
            "import faiss\n",
            "import numpy as np\n",
            "dimension = 128\n",
            "num_vectors = 1000000\n",
            "vectors = np.random.random((num_vectors, \n",
            "dimension)).astype('float32')\n",
            "# Create HNSW index\n",
            "M = 16    # Number of connections per layer\n",
            "efC = 100  # Construction-time exploration factor\n",
            "index_hnsw = faiss.IndexHNSWFlat(dimension, M)\n",
            "index_hnsw.hnsw.efConstruction = efC\n",
            "index_hnsw.hnsw.efSearch = 64  # Search-time exploration factor\n",
            "# Add vectors (no separate training needed)\n",
            "index_hnsw.add(vectors)\n",
            "Tuning HNSW Parameters\n",
            "•M (connections per node): Higher values = better accuracy but more memory\n",
            "•Typical values: 16-64\n",
            "•efConstruction (build-time accuracy): Higher values = better index quality but \n",
            "slower build\n",
            "•Typical values: 100-500\n",
            "•efSearch (search-time accuracy): Higher values = better search accuracy but \n",
            "slower search\n",
            "•Can be adjusted at query time\n",
            "Advantages\n",
            "•Excellent balance of speed and accuracy\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 15:**\n",
            "•Excellent balance of speed and accuracy\n",
            "•No training phase required\n",
            "•Dynamic updates possible (can add vectors after construction)\n",
            "•Works well with filtered queries\n",
            "Disadvantages\n",
            "•Memory intensive (stores both vectors and graph links)\n",
            "•Index construction can be slow\n",
            "•More complex implementation than other methodsSTATFUSIONAISCALAR QUANTIZATION (SQ)\n",
            "What is Scalar Quantization?\n",
            "Scalar Quantization reduces the precision of vector components (e.g., from 32-bit \n",
            "float to 8-bit integer) to decrease memory usage while maintaining reasonable \n",
            "accuracy.\n",
            "When to Use SQ\n",
            "•When you need moderate memory savings with minimal accuracy loss\n",
            "•As a simpler alternative to PQ when extreme compression isn't needed\n",
            "•Can be combined with other index types (Flat-SQ, IVF-SQ, etc.)\n",
            "How SQ Works\n",
            "1.Determine the range of values in each dimension\n",
            "2.Map these ranges to fixed-bit representations (typically 8-bit)\n",
            "3.Convert each floating-point value to its quantized form\n",
            "Distance Considerations\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 16:**\n",
            "Distance Considerations\n",
            "•Works with both L2 distance and inner product (cosine similarity)\n",
            "•Slightly reduced accuracy due to quantization error\n",
            "•Computations may be faster due to integer arithmetic\n",
            "Implementation Example (FAISS)\n",
            "import faiss\n",
            "import numpy as np\n",
            "dimension = 128\n",
            "num_vectors = 1000000\n",
            "vectors = np.random.random((num_vectors, \n",
            "dimension)).astype('float32')\n",
            "# Create Scalar Quantized index\n",
            "index_sq = faiss.IndexScalarQuantizer(dimension, \n",
            "faiss.ScalarQuantizer.QT_8bit, faiss.METRIC_L2)\n",
            "# Alternative: combine with IVF\n",
            "quantizer = faiss.IndexFlatL2(dimension)\n",
            "index_ivfsq = faiss.IndexIVFScalarQuantizer(quantizer, dimension, 1000, \n",
            "                                           faiss.ScalarQuantizer.QT_8bit, faiss.METRIC_L2)\n",
            "# Train and add vectors\n",
            "index_ivfsq.train(vectors[:100000])\n",
            "index_ivfsq.add(vectors)\n",
            "Advantages\n",
            "•Simple implementation and concept\n",
            "•Moderate memory savings (4x compared to 32-bit floats)\n",
            "•Minimal accuracy impact\n",
            "Disadvantages\n",
            "•Less compression than PQ\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 17:**\n",
            "Disadvantages\n",
            "•Less compression than PQ\n",
            "•Still requires significant memory for large datasets\n",
            "STATFUSIONAIVECTORDB SPECIFIC INDEXING FEATURES\n",
            "Vector \n",
            "DatabaseSupported \n",
            "Index TypesDistance \n",
            "MetricsAuto-Indexing? Key Features\n",
            "FAISS Flat, IVF, PQ, \n",
            "HNSW, SQ, LSH, \n",
            "combinationsL2, Cosine, Dot \n",
            "Product\n",
            "Highly \n",
            "customizable, \n",
            "GPU support\n",
            "Pinecone Proprietary \n",
            "(HNSW-based)Cosine, Dot \n",
            "Product, \n",
            "Euclidean\n",
            "Fully managed, \n",
            "serverless, auto-\n",
            "scaling\n",
            "Weaviate HNSW, Flat Cosine\n",
            " Schema-based, \n",
            "multi-modal, \n",
            "GraphQL API\n",
            "Qdrant HNSW, Scalar \n",
            "QuantizationCosine, Dot \n",
            "Product, \n",
            "Euclidean\n",
            "payload storage\n",
            "Milvus IVF, HNSW, \n",
            "PQ, ANNOY, \n",
            "combinationsEuclidean, IP, \n",
            "Jaccard, others\n",
            "Hybrid search, \n",
            "cloud/self-\n",
            "hosted\n",
            "Chroma HNSW Cosine, L2, IP\n",
            " Simple API, \n",
            "embedding \n",
            "function \n",
            "integration\n",
            "Elasticsearch HNSW Cosine, Dot \n",
            "Product, L2\n",
            "Text+vector \n",
            "search, mature \n",
            "ecosystem\n",
            "pgvector IVF, HNSW Cosine, L2, IP\n",
            " Postgres \n",
            "extension, \n",
            "familiar SQL \n",
            "interfaceMajor Vector Database Comparison\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 18:**\n",
            "interfaceMajor Vector Database Comparison\n",
            "STATFUSIONAISpecial Features by Database\n",
            "FAISS\n",
            "•Supports GPU acceleration for both indexing and search\n",
            "•Provides multi-GPU and distributed search capabilities\n",
            "•Allows custom combination of index types (e.g., IVF + PQ + SQ)\n",
            "Pinecone\n",
            "1.Automatic index selection and optimization\n",
            "2.Namespace support for logical data separation\n",
            "3.Handles pod-based scaling for high throughput\n",
            "Weaviate\n",
            "•Modular architecture with multi-modal search\n",
            "•Contextionization for dynamic vector generation\n",
            "•BM25/TF-IDF hybrid search with vector search\n",
            "Qdrant\n",
            "•Advanced payload filtering with vector search\n",
            "•Payload-based negative filtering for search results\n",
            "•Optimized disk storage with memory-mapped files\n",
            "Milvus\n",
            "•Dynamic schema changes without reindexing\n",
            "•Scalar, vector, and hybrid search capabilities\n",
            "•Time travel queries (historical data access)\n",
            "STATFUSIONAICHOOSING THE RIGHT INDEX\n",
            "Decision Framework\n",
            "Guidance by Data SizeQuestion Use Case Example Recommended\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 19:**\n",
            "IndexDistance Metric\n",
            "Do you need 100% \n",
            "accuracy?Financial transaction \n",
            "matchingFlat Index Typically L2 or cosine\n",
            "Do you have millions \n",
            "of vectors?Large-scale \n",
            "semantic searchIVF or HNSW Cosine for text, L2 for \n",
            "images\n",
            "Is speed more \n",
            "important than \n",
            "accuracy?Real-time product \n",
            "recommendationsHNSW Cosine similarity\n",
            "Are you on low \n",
            "memory hardware?Mobile or embedded \n",
            "searchIVF-PQ or SQ L2 often preferred\n",
            "Do you need \n",
            "incremental \n",
            "updates?Dynamic document \n",
            "databaseHNSW Any, depending on \n",
            "data\n",
            "Is your data high-\n",
            "dimensional (500+)?Large language \n",
            "model embeddingsPQ + IVF Cosine similarity\n",
            "Dataset Size First Choice Alternative Notes\n",
            "< 100K vectors Flat HNSW Flat for simplicity, \n",
            "HNSW if query speed \n",
            "critical\n",
            "100K - 1M vectors HNSW IVF HNSW for better \n",
            "accuracy-speed \n",
            "tradeoff\n",
            "1M - 10M vectors IVF-HNSW IVF Combined approach \n",
            "for balanced \n",
            "performance\n",
            "10M - 100M vectors IVF-PQ IVF-SQ Compression \n",
            "becomes necessary\n",
            "> 100M vectors IVF-PQ Distributed HNSW Must consider \n",
            "distribution \n",
            "or extreme\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 20:**\n",
            "distribution \n",
            "or extreme \n",
            "compression\n",
            "STATFUSIONAIHOW INDEXING WORKS \n",
            "– FAISS EXAMPLE\n",
            "Code:\n",
            "import faiss\n",
            "import numpy as np\n",
            "# Convert embeddings to numpy array (float32 required by FAISS)\n",
            "embeddings_np = np.array(embeddings).astype('float32')\n",
            "# Get dimensionality of vectors\n",
            "d = embeddings_np.shape[1]  # 384 dimensions\n",
            "# Create a flat index (brute force search)\n",
            "index = faiss.IndexFlatL2(d)  # L2 = Euclidean distance\n",
            "# Add vectors to the index\n",
            "index.add(embeddings_np)\n",
            "Behind the Scenes: \n",
            "•FAISS creates a data structure to efficiently find similar vectors\n",
            "•For a Flat index:\n",
            "•Vectors are stored contiguously in memory for cache efficiency\n",
            "•Uses SIMD (Single Instruction Multiple Data) for parallel computation\n",
            "•Calculates distances between ALL vectors during search (brute force)\n",
            "•For more advanced indices like HNSW:\n",
            "•Builds a navigable graph structure with multiple layers\n",
            "•Vectors become nodes connected to similar vectors\n",
            "•Search follows connections to quickly find similar vectors\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 21:**\n",
            "Output Example:\n",
            "print(f\"FAISS index contains {index.ntotal} vectors of dimension {d}\")\n",
            "# FAISS index contains 3 vectors of dimension 384\n",
            "STATFUSIONAICREATING ADVANCED INDICES \n",
            "FOR FASTER RETRIEVAL\n",
            "Code:\n",
            "# Create an HNSW index (much faster for large datasets)\n",
            "nlist = 1     # Number of clusters (use higher for millions of vectors)\n",
            "M = 16        # Number of connections per layer (higher = more \n",
            "accurate, slower)\n",
            "ef_construction = 200  # Controls index quality\n",
            "index_hnsw = faiss.IndexHNSWFlat(d, M)\n",
            "index_hnsw.hnsw.efConstruction = ef_construction\n",
            "index_hnsw.add(embeddings_np)\n",
            "Behind the Scenes: \n",
            "•Hierarchical Navigable Small World creates a multi-layer graph\n",
            "•Each vector connects to M most similar vectors\n",
            "•Creates \"shortcuts\" through vector space\n",
            "•During construction:\n",
            "1.Insert vector at top layer\n",
            "2.Navigate down through layers using greedy search\n",
            "3.Connect to nearest neighbors at each layer\n",
            "4.Maintain max connections per node (M)\n",
            "Visualization:\n",
            "Layer 2:  •───•\n",
            "                 │\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 22:**\n",
            "Layer 2:  •───•\n",
            "                 │   \n",
            "Layer 1:  •───•───•\n",
            "                 │   │   │\n",
            "Layer 0:  •───•───•───•───•───•\n",
            "               All vectors in bottom layer\n",
            "STATFUSIONAIRETRIEVING \n",
            "SIMILAR CHUNKS\n",
            "Code:\n",
            "# Create a query vector\n",
            "query_text = \"Which fruit is red?\"\n",
            "query_vector = model.encode([query_text])[0].astype('float32')\n",
            "# Search the index\n",
            "k = 2  # Return top 2 results\n",
            "distances, indices = \n",
            "index.search(np.array([query_vector]).astype('float32'), k)\n",
            "# Display results\n",
            "print(f\"Top {k} matches for '{query_text}':\")\n",
            "for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n",
            "    print(f\"{i+1}. Text: '{texts[idx]}' (Distance: {dist:.4f})\")\n",
            "Behind the Scenes: \n",
            "1.Query text is converted to a vector using same model\n",
            "2.Vector DB performs distance calculations:\n",
            "•For Flat index: Computes distance to EVERY vector (O(n))\n",
            "•For HNSW index: Traverses graph structure (O(log n))\n",
            "3.  Returns indices of closest vectors and their distances\n",
            "Output:\n",
            "Top 2 matches for 'Which fruit is red?':\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 23:**\n",
            "Output:\n",
            "Top 2 matches for 'Which fruit is red?':\n",
            "1. Text: 'Apples are sweet and red.' (Distance: 0.7234)\n",
            "2. Text: 'Bananas are yellow and soft.' (Distance: 1.2156)\n",
            "STATFUSIONAIHOW SIMILARITY IS \n",
            "CALCULATED\n",
            "Mathematical Understanding:\n",
            "•Euclidean: Straight-line distance between points in vector space\n",
            "•Formula: sqrt(sum((a_i - b_i)²))\n",
            "•Cosine: Angle between vectors (ignores magnitude)\n",
            "•Formula: dot(a, b) / (||a|| * ||b||)\n",
            "•After normalization, dot product = cosine similarityDifferent similarity metrics can be used, affecting how \"closeness\" is measured:\n",
            "Euclidean Distance (L2):\n",
            "# Already used in our FAISS example\n",
            "index = faiss.IndexFlatL2(d)  # Lower value = more similar\n",
            "Cosine Similarity:\n",
            "# Normalize vectors for cosine similarity\n",
            "faiss.normalize_L2(embeddings_np)  # In-place normalization\n",
            "# Create index that measures inner product (dot product)\n",
            "index_ip = faiss.IndexFlatIP(d)    # Higher value = more similar\n",
            "index_ip.add(embeddings_np)        # Add normalized vectors\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 24:**\n",
            "# Normalize query for search\n",
            "query_vector_norm = query_vector.copy()\n",
            "faiss.normalize_L2(np.array([query_vector_norm]).astype('float32'))\n",
            "STATFUSIONAIREAL-WORLD USE CASE: \n",
            "BUILDING A SIMPLE Q&A SYSTEM\n",
            "Complete Working Example:\n",
            "import numpy as np\n",
            "from sentence_transformers import SentenceTransformer\n",
            "import faiss\n",
            "# 1. Create a knowledge base\n",
            "documents = [\n",
            "    \"Apples are red or green fruits that grow on trees.\",\n",
            "    \"Bananas are yellow fruits with a soft texture inside.\",\n",
            "    \"Oranges are citrus fruits known for vitamin C content.\",\n",
            "    \"Strawberries are red berries with seeds on the outside.\",\n",
            "    \"Blueberries are small blue fruits rich in antioxidants.\"\n",
            "]\n",
            "# 2. Convert to embeddings\n",
            "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
            "document_embeddings = \n",
            "model.encode(documents).astype('float32')\n",
            "# 3. Create and populate index\n",
            "dimension = document_embeddings.shape[1]\n",
            "index = faiss.IndexFlatL2(dimension)\n",
            "index.add(document_embeddings)\n",
            "# 4. Function to answer questions\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 25:**\n",
            "# 4. Function to answer questions\n",
            "def answer_question(question, index, documents, model, k=2):\n",
            "    # Convert question to vector\n",
            "    query_vector = model.encode([question]).astype('float32')\n",
            "STATFUSIONAI    # Search\n",
            "    distances, indices = index.search(query_vector, k)\n",
            "    \n",
            "    print(f\"Question: {question}\\n\")\n",
            "    print(\"Top relevant information:\")\n",
            "    for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):\n",
            "        print(f\"{i+1}. {documents[idx]} (Distance: {dist:.4f})\")\n",
            "    \n",
            "    print(\"\\n---\\n\")\n",
            "# 5. Try it out\n",
            "questions = [\n",
            "    \"What color are apples?\"\n",
            "]\n",
            "for question in questions:\n",
            "    answer_question(question, index, documents, model)\n",
            "System Output:\n",
            "Question: What color are apples?\n",
            "Top relevant information:\n",
            "1. Apples are red or green fruits that grow on trees. (Distance: 0.5008)\n",
            "2. Bananas are yellow fruits with a soft texture inside. (Distance: 1.0824)\n",
            "STATFUSIONAIREAL-LIFE ANALOGY\n",
            "Vector databases are like Google Maps for ideas:\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 26:**\n",
            "Vector databases are like Google Maps for ideas:\n",
            "•Vector space is like a vast landscape of meaning\n",
            "•Embedding model is like a coordinate system\n",
            "•Indexing creates highways and shortcuts for faster travel\n",
            "•Query is your starting point\n",
            "•Similarity search finds the closest \"locations\" in meaning-space\n",
            "•\n",
            "Applications:\n",
            "•Semantic search engines\n",
            "•Chatbot memory & knowledge retrieval\n",
            "•Recommendation systems\n",
            "•Content discovery\n",
            "•Document deduplication\n",
            "STATFUSIONAISUMMARY\n",
            "Key Insight:  Vector databases bridge the gap between human language and    \n",
            "machine understanding, enabling semantic search beyond keyword matching.Step Descr iption Code E xample What Happens\n",
            "1. Embedding Convert t ext to vec-\n",
            "torsmodel.enc ode(t exts) Neur al netw ork tr ansf orms \n",
            "text to numeric al represen -\n",
            "tation\n",
            "2. St orage Save v ectors in DB collection.add(...) Vectors st ored in specializ ed \n",
            "structures + metadata in KV \n",
            "store\n",
            "3. Inde xing\n",
            "search structurefaiss.In -\n",
            "dexHNSWFlat(d, M)Creat es gr aph or clust ers f or\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 **Chunk 27:**\n",
            "fast na vigation\n",
            "4. Quer y Convert question t o \n",
            "vectormodel.enc ode([que-\n",
            "ry])Same proc ess as original t ext\n",
            "5. Retrie val Find similar v ectors inde x.search(que -\n",
            "ry_vector, k)Finds nearest neighbors us-\n",
            "ing distanc e metric\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting Chunks into embeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "def generate_embeddings(chunks):\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "    return embedding_model, chunks\n",
        "\n",
        "embedding_model, chunks = generate_embeddings(chunks)"
      ],
      "metadata": {
        "id": "2uau3WPduAN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing embeddings in Faiss vectordb\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def store_in_db(chunks, embedding_model):\n",
        "    vector_db = FAISS.from_documents(chunks, embedding_model)\n",
        "    return vector_db\n",
        "\n",
        "vector_db = store_in_db(chunks, embedding_model)"
      ],
      "metadata": {
        "id": "Yrf7dUdAuAQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting query into embeddings\n",
        "def query_to_embeddings(query, embedding_model):\n",
        "    query_embedding = embedding_model.embed_query(query)\n",
        "    return query_embedding\n",
        "\n",
        "query = \"give me different types of vector indexing and uses?\"\n",
        "query_embedding = query_to_embeddings(query, embedding_model)"
      ],
      "metadata": {
        "id": "rCq0oQkQuQZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#retrieving top matched context from vectordb\n",
        "def retrieve_top_matches(vector_db, query_embedding):\n",
        "    top_matches = vector_db.similarity_search_by_vector(query_embedding, k=3)\n",
        "    return top_matches\n",
        "\n",
        "top_matches = retrieve_top_matches(vector_db, query_embedding)\n",
        "print(top_matches)"
      ],
      "metadata": {
        "id": "cnIKOYUjuQc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sending retrieved context to llm\n",
        "from groq import Groq\n",
        "\n",
        "def pass_to_llm(query, top_matches, api_key):\n",
        "    context = \"\\n\\n\".join(match.page_content for match in top_matches)\n",
        "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
        "    client = Groq(api_key=api_key)\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        model=\"gemma2-9b-it\"\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content, top_matches\n",
        "\n",
        "\n",
        "api_key=\"your_api_key\"\n",
        "llm_response, top_matches = pass_to_llm(query, top_matches, api_key)\n",
        "print(llm_response)"
      ],
      "metadata": {
        "id": "JWTa93Z7uQjt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}